{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "rcParams['figure.figsize']=14,6\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('picklefile/prepare_data_set.pickle', 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['sentiment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This kindle is light and easy to use especiall...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didnt know how much i'd use a kindle so went f...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am 100 happy with my purchase. I caught it o...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solid entry level Kindle. Great for kids. Gift...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This make an excellent ebook reader. Don't exp...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  rating  sentiment  \\\n",
       "0  This kindle is light and easy to use especiall...     5.0          1   \n",
       "1  Didnt know how much i'd use a kindle so went f...     4.0          1   \n",
       "2  I am 100 happy with my purchase. I caught it o...     5.0          1   \n",
       "3  Solid entry level Kindle. Great for kids. Gift...     5.0          1   \n",
       "4  This make an excellent ebook reader. Don't exp...     5.0          1   \n",
       "\n",
       "   text length  \n",
       "0           63  \n",
       "1          107  \n",
       "2          757  \n",
       "3          176  \n",
       "4          158  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I was looking for a kindle whitepaper. I saw o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Looking at the picture and seeing it was 8th g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>it would not load my books proper. took a doze...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>The screen is too dark, and cannot adjust the ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>I have to say it was a little confusing and fr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Poor quality. It has not been few months and i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Sound quality is not good at all. Muddy sound ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>flimsy product, dispite of minimal use, rubber...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8694</th>\n",
       "      <td>Bass effect very low. Spend some more bucks an...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>Already replaced the product ones. But the new...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  rating  sentiment  \\\n",
       "18    I was looking for a kindle whitepaper. I saw o...     1.0          0   \n",
       "67    Looking at the picture and seeing it was 8th g...     1.0          0   \n",
       "75    it would not load my books proper. took a doze...     2.0          0   \n",
       "86    The screen is too dark, and cannot adjust the ...     2.0          0   \n",
       "136   I have to say it was a little confusing and fr...     2.0          0   \n",
       "...                                                 ...     ...        ...   \n",
       "8691  Poor quality. It has not been few months and i...     1.0          0   \n",
       "8692  Sound quality is not good at all. Muddy sound ...     1.0          0   \n",
       "8693  flimsy product, dispite of minimal use, rubber...     1.0          0   \n",
       "8694  Bass effect very low. Spend some more bucks an...     2.0          0   \n",
       "8695  Already replaced the product ones. But the new...     1.0          0   \n",
       "\n",
       "      text length  \n",
       "18            511  \n",
       "67            651  \n",
       "75             96  \n",
       "86             56  \n",
       "136           420  \n",
       "...           ...  \n",
       "8691          142  \n",
       "8692          124  \n",
       "8693          127  \n",
       "8694           75  \n",
       "8695          121  \n",
       "\n",
       "[4010 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8696, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Buy associate explained product very well. Easy to use'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1208]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[459]['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train data and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 6522 training examples and 2174 validation examples. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'],df['sentiment'], test_size=0.25, random_state=101)\n",
    "\n",
    "print('Loading %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Creating a function to do text preprocessing\n",
    "## 2. Remove non-character such as digits and symbols\n",
    "## 3. Convert to lower case\n",
    "## 4. Remove stop words such as \"the\" and \"and\" if needed\n",
    "## 5. Convert to root words by stemming if needed\n",
    "\n",
    "def cleanText(text, remove_stopwords=True, Lemmatization=True):\n",
    "    \n",
    "    # Removing non-character\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # converting to lower case\n",
    "    words = letters_only.lower().split()  \n",
    "    \n",
    "    \n",
    "    #Lemmatization\n",
    "    if Lemmatization==True: \n",
    "        Lemmatizer = WordNetLemmatizer() \n",
    "        words = [Lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "    # Removing stopword\n",
    "    if remove_stopwords==True: \n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # Stemming\n",
    "    #if stemming==True: \n",
    "     #   stemmer = PorterStemmer('english') \n",
    "     #   words = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing a cleaned review in the training set : \n",
      "\n",
      " love amazon echo plus bad sound get bed turn light fan even tv love alexa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing text data in training set and validation set\n",
    "\n",
    "X_train_cleaned = []\n",
    "X_test_cleaned = []\n",
    "\n",
    "for d in X_train:\n",
    "    X_train_cleaned.append(cleanText(d))\n",
    "print('Showing a cleaned review in the training set : \\n\\n',  X_train_cleaned[344])\n",
    "    \n",
    "for d in X_test:\n",
    "    X_test_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 6395 \n",
      "\n",
      "Show some feature names : \n",
      " ['aa', 'batery', 'clip', 'detailed', 'exactly', 'grate', 'item', 'mickey', 'perchues', 'receptive', 'shes', 'surroundings', 'usual']\n"
     ]
    }
   ],
   "source": [
    "# Fitting and transform the training data to a document-term matrix using CountVectorizer\n",
    "\n",
    "countVect = CountVectorizer() \n",
    "X_train_countVect = countVect.fit_transform(X_train_cleaned)\n",
    "\n",
    "#Showing what are the words which are given much importance by the model\n",
    "print(\"Number of features : %d \\n\" %len(countVect.get_feature_names()))  \n",
    "print(\"Show some feature names : \\n\", countVect.get_feature_names()[::500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_countVect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline_lr = Pipeline([('lr_classifier',LogisticRegression(random_state=0))])\n",
    "\n",
    "pipeline_dt = Pipeline([('dt_classifier',DecisionTreeClassifier())])\n",
    "\n",
    "pipeline_rf = Pipeline([('rf_classifier',RandomForestClassifier())])\n",
    "\n",
    "pipeline_mnb = Pipeline([('mnb_classifier',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_lr,pipeline_dt,pipeline_rf,pipeline_mnb]\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\"\n",
    "pipe_dict = {0:'Logistic Regression',1:'Decision Tree',2:'RandomForest',3:'MultiNomialNB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train_countVect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9415823367065317\n",
      "Decision Tree Test Accuracy: 0.890984360625575\n",
      "RandomForest Test Accuracy: 0.9443422263109476\n",
      "MultiNomialNB Test Accuracy: 0.9314627414903404\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(countVect.transform(X_test_cleaned),y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:RandomForest\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(countVect.transform(X_test_cleaned),y_test)>best_accuracy:\n",
    "        best_accuracy = model.score(countVect.transform(X_test_cleaned),y_test)\n",
    "        best_classifier = i\n",
    "        best_pipeline = model\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_countVect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEvaluation(predictions):\n",
    "    \n",
    "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on validation set: 0.9430\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1010\n",
      "           1       0.94      0.96      0.95      1164\n",
      "\n",
      "    accuracy                           0.94      2174\n",
      "   macro avg       0.94      0.94      0.94      2174\n",
      "weighted avg       0.94      0.94      0.94      2174\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      " [[ 937   73]\n",
      " [  51 1113]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validaton set\n",
    "\n",
    "predictions = classifier.predict(countVect.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'much', 'satisfied', 'super', 'fast', 'processing', 'awesome', 'screen', 'color', 'robust', 'build', 'good', 'keyboard', 'touch', 'pad', 'good', 'productivity', 'stuff', 'like', 'video', 'editing', 'animation', 'software', 'graphic', 'software', 'heavy', 'coding', 'environment', 'course', 'game']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\" Pretty much satisfied.\n",
    "Super fast processing, awesome screen colors, robust build, good keyboard and touch pad.\n",
    "Good for all the productivity stuff like video editing, animation softwares, graphics software, heavy coding environments and off course games\"\"\"\n",
    "clean_text = cleanText(text)\n",
    "clean_text1 = clean_text.split()\n",
    "print(clean_text1)\n",
    "pred = classifier.predict(countVect.transform(clean_text1))\n",
    "\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29,  1], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "End_prediction = np.bincount(pred)\n",
    "End_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\n",
      "Positive words: 1\n",
      "Negative words: 29\n",
      "Sorry for the inconvenience. Our support staff will contact you and sort out the problem.\n"
     ]
    }
   ],
   "source": [
    "End_prediction = np.bincount(pred)\n",
    "End_prediction_dict = {0:End_prediction[0],1:End_prediction[1]}\n",
    "if End_prediction_dict[0] > End_prediction_dict[1]: \n",
    "    print(np.delete(End_prediction,1))\n",
    "    print(\"Positive words:\",End_prediction_dict[1])\n",
    "    print(\"Negative words:\",End_prediction_dict[0])\n",
    "    print(\"Sorry for the inconvenience. Our support staff will contact you and sort out the problem.\")\n",
    "else:\n",
    "    print(\"Positive words:\",End_prediction_dict[1])\n",
    "    print(\"Negative words:\",End_prediction_dict[0])\n",
    "    print(\"Thank You for your feedback!ðŸ˜Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 2394 \n",
      "\n",
      "Show some feature names : \n",
      " ['00', 'here', 'station']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Fit and transform the training data to a document-term matrix using TfidfVectorizer \n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5) # Taking a minimum document frequency of 5\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "print(\"Number of features : %d \\n\" %len(tfidf.get_feature_names()))\n",
    "print(\"Show some feature names : \\n\", tfidf.get_feature_names()[::1000])\n",
    "\n",
    "#  Instatiating and fitting Logistic Regression object\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features with smallest coefficients :\n",
      "['not' 'batteries' 'slow' 'returned' 'disappointed' 'after' 'don' 'poor'\n",
      " 'return' 'charge']\n",
      "\n",
      "Top 10 features with largest coefficients : \n",
      "['great' 'love' 'easy' 'echo' 'alexa' 'my' 'well' 'gift' 'loves' 'tablet']\n"
     ]
    }
   ],
   "source": [
    "# Looking at the top 10 features with smallest and the largest coefficients\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "sorted_coef_index = lr.coef_[0].argsort()\n",
    "print('\\nTop 10 features with smallest coefficients :\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Top 10 features with largest coefficients : \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best paramenter set is : \n",
      " {'lr__C': 10, 'tfidf__max_features': None, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
      "\n",
      "Accuracy on validation set: 0.9512\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1010\n",
      "           1       0.95      0.96      0.95      1164\n",
      "\n",
      "    accuracy                           0.95      2174\n",
      "   macro avg       0.95      0.95      0.95      2174\n",
      "weighted avg       0.95      0.95      0.95      2174\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      " [[ 947   63]\n",
      " [  43 1121]]\n"
     ]
    }
   ],
   "source": [
    "estimators = [(\"tfidf\", TfidfVectorizer()), (\"lr\", LogisticRegression())]\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "\n",
    "# Grid search\n",
    "params = {\"lr__C\":[0.1, 1, 10], #regularization param of logistic regression\n",
    "          \"tfidf__min_df\": [1, 3], #min count of words \n",
    "          \"tfidf__max_features\": [1000, None], #max features\n",
    "          \"tfidf__ngram_range\": [(1,1), (1,2)], #1-grams or 2-grams\n",
    "          \"tfidf__stop_words\": [None, \"english\"]} #use stopwords or don't\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid.fit(X_train_cleaned, y_train)\n",
    "print(\"The best paramenter set is : \\n\", grid.best_params_)\n",
    "\n",
    "\n",
    "# Evaluate on the validaton set\n",
    "predictions = grid.predict(X_test_cleaned)\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'much', 'satisfied', 'super', 'fast', 'processing', 'awesome', 'screen', 'color', 'robust', 'build', 'good', 'keyboard', 'touch', 'pad', 'good', 'productivity', 'stuff', 'like', 'video', 'editing', 'animation', 'software', 'graphic', 'software', 'heavy', 'coding', 'environment', 'course', 'game']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Pretty much satisfied.\n",
    "Super fast processing, awesome screen colors, robust build, good keyboard and touch pad.\n",
    "Good for all the productivity stuff like video editing, animation softwares, graphics software, heavy coding environments and off course games\"\"\"\n",
    "clean_text = cleanText(text)\n",
    "clean_text1 = clean_text.split()\n",
    "print(clean_text1)\n",
    "pred1 = grid.predict(clean_text1)\n",
    "\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 15], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "End_prediction = np.bincount(pred1)\n",
    "End_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words: 15\n",
      "Negative words: 15\n",
      "It is a positive review\n"
     ]
    }
   ],
   "source": [
    "End_prediction = np.bincount(pred1)\n",
    "End_prediction_dict = {0:End_prediction[0],1:End_prediction[1]}\n",
    "if End_prediction_dict[0] > End_prediction_dict[1]: \n",
    "    print(np.delete(End_prediction,1))\n",
    "    print(\"Positive words:\",End_prediction_dict[1])\n",
    "    print(\"Negative words:\",End_prediction_dict[0])\n",
    "    print(\"it may be a negative review or compliant or both\")\n",
    "else:\n",
    "    print(\"Positive words:\",End_prediction_dict[1])\n",
    "    print(\"Negative words:\",End_prediction_dict[0])\n",
    "    print(\"It is a positive review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
